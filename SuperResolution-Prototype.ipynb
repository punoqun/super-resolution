{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.utils.data as data\n",
    "from math import log10\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_img(filepath):\n",
    "    \"\"\"Load image and convert to YCbCr color space.\n",
    "    Returns Y, Cb, and Cr channels separately.\"\"\"\n",
    "    img = Image.open(filepath).convert('YCbCr')\n",
    "    y, cb, cr = img.split()\n",
    "    return y, cb, cr\n",
    "    \n",
    "class SuperResolutionDataset(Dataset):\n",
    "    \"\"\"Dataset for super-resolution that processes Y channel through the network\n",
    "    and upscales Cb/Cr channels using bicubic interpolation.\"\"\"\n",
    "    \n",
    "    def __init__(self, root_dir, input_transform=None, target_transform=None):\n",
    "        self.input_transform = input_transform\n",
    "        self.target_transform = target_transform\n",
    "        self.root_dir = root_dir\n",
    "        self.img_list = [join(root_dir, x) for x in listdir(root_dir)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Load all three channels\n",
    "        y, cb, cr = load_img(self.img_list[idx])\n",
    "        \n",
    "        # Create input (downsampled Y channel)\n",
    "        input_y = y.copy()\n",
    "        if self.input_transform:\n",
    "            input_y = self.input_transform(input_y)\n",
    "        \n",
    "        # Create target (full resolution Y channel)\n",
    "        target_y = y\n",
    "        if self.target_transform:\n",
    "            target_y = self.target_transform(target_y)\n",
    "        \n",
    "        return input_y, target_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_training_set(root_dir):\n",
    "    train_dir = join(root_dir, \"train\")\n",
    "\n",
    "    return SuperResolutionDataset(train_dir,\n",
    "                             input_transform=transforms.Compose([\n",
    "                                transforms.Resize((540,960)),\n",
    "                                transforms.ToTensor()]),\n",
    "                             target_transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "def get_test_set(root_dir):\n",
    "    test_dir = join(root_dir, \"test\")\n",
    "\n",
    "    return SuperResolutionDataset(test_dir,\n",
    "                             input_transform=transforms.Compose([\n",
    "                                transforms.Resize((540,960)),\n",
    "                                transforms.ToTensor()]),\n",
    "                             target_transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "import torch.optim as optim\n",
    "model = Net(upscale_factor=2).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_set = get_training_set('./1080Dataset/')\n",
    "test_set = get_test_set('./1080Dataset/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    epoch_loss = 0\n",
    "    for iteration, batch in enumerate(train_loader, 1):\n",
    "        input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(input), target)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(train_loader), loss.item()))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(train_loader)))\n",
    "\n",
    "def test():\n",
    "    avg_psnr = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in test_loader:\n",
    "            input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            prediction = model(input)\n",
    "            mse = criterion(prediction, target)\n",
    "            psnr = 10 * log10(1 / mse.item())\n",
    "            avg_psnr += psnr\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(test_loader)))\n",
    "\n",
    "\n",
    "def checkpoint(epoch):\n",
    "    model_out_path = \"model_epoch_{}.pth\".format(epoch)\n",
    "    torch.save(model, model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_color_image(y_channel, cb_channel, cr_channel):\n",
    "    \"\"\"Reconstruct a color image from Y, Cb, and Cr channels.\n",
    "    \n",
    "    Args:\n",
    "        y_channel: Super-resolved Y channel (tensor or PIL Image)\n",
    "        cb_channel: Cb channel (should be upscaled to match Y size)\n",
    "        cr_channel: Cr channel (should be upscaled to match Y size)\n",
    "    \n",
    "    Returns:\n",
    "        RGB PIL Image\n",
    "    \"\"\"\n",
    "    # Convert tensors to PIL Images if needed\n",
    "    if torch.is_tensor(y_channel):\n",
    "        y_channel = transforms.ToPILImage()(y_channel.cpu())\n",
    "    if torch.is_tensor(cb_channel):\n",
    "        cb_channel = transforms.ToPILImage()(cb_channel.cpu())\n",
    "    if torch.is_tensor(cr_channel):\n",
    "        cr_channel = transforms.ToPILImage()(cr_channel.cpu())\n",
    "    \n",
    "    # Ensure all channels have the same size\n",
    "    target_size = y_channel.size\n",
    "    if cb_channel.size != target_size:\n",
    "        cb_channel = cb_channel.resize(target_size, Image.BICUBIC)\n",
    "    if cr_channel.size != target_size:\n",
    "        cr_channel = cr_channel.resize(target_size, Image.BICUBIC)\n",
    "    \n",
    "    # Merge channels and convert to RGB\n",
    "    ycbcr_image = Image.merge('YCbCr', [y_channel, cb_channel, cr_channel])\n",
    "    rgb_image = ycbcr_image.convert('RGB')\n",
    "    \n",
    "    return rgb_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 100):\n",
    "    train(epoch)\n",
    "    test()\n",
    "    checkpoint(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}