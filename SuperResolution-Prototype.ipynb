{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function, division\n",
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch.utils.data as data\n",
    "\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from PIL import Image\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.ion()   # interactive mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def load_img(filepath):\n",
    "    img = Image.open(filepath).convert('YCbCr')\n",
    "    y, _, _ = img.split()\n",
    "    return y\n",
    "    \n",
    "class SuperResolutionDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, root_dir, input_transform=None, output_transform=None):\n",
    "        self.input_transform = input_transform\n",
    "        self.output_transform = output_transform\n",
    "        self.root_dir = root_dir\n",
    "        self.img_list = [join(root_dir, x) for x in listdir(root_dir)]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.img_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        x2image = load_img(self.img_list[idx])\n",
    "        image = x2image.copy()\n",
    "        if self.input_transform:\n",
    "            image = self.input_transform(image)\n",
    "        if self.output_transform:\n",
    "            x2image = self.output_transform(x2image)\n",
    "        \n",
    "        return image, x2image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_training_set(root_dir):\n",
    "    train_dir = join(root_dir, \"train\")\n",
    "\n",
    "    return SuperResolutionDataset(train_dir,\n",
    "                             input_transform=transforms.Compose([\n",
    "                                transforms.Resize((540,960)),\n",
    "                                transforms.ToTensor()]),\n",
    "                             output_transform=transforms.ToTensor())\n",
    "\n",
    "\n",
    "def get_test_set(root_dir):\n",
    "    test_dir = join(root_dir, \"test\")\n",
    "\n",
    "    return SuperResolutionDataset(test_dir,\n",
    "                             input_transform=transforms.Compose([\n",
    "                                transforms.Resize((540,960)),\n",
    "                                transforms.ToTensor()]),\n",
    "                             output_transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.init as init\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, upscale_factor):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.conv1 = nn.Conv2d(1, 64, (5, 5), (1, 1), (2, 2))\n",
    "        self.conv2 = nn.Conv2d(64, 64, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv3 = nn.Conv2d(64, 32, (3, 3), (1, 1), (1, 1))\n",
    "        self.conv4 = nn.Conv2d(32, upscale_factor ** 2, (3, 3), (1, 1), (1, 1))\n",
    "        self.pixel_shuffle = nn.PixelShuffle(upscale_factor)\n",
    "\n",
    "        self._initialize_weights()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        x = self.relu(self.conv3(x))\n",
    "        x = self.pixel_shuffle(self.conv4(x))\n",
    "        return x\n",
    "\n",
    "    def _initialize_weights(self):\n",
    "        init.orthogonal_(self.conv1.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv2.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv3.weight, init.calculate_gain('relu'))\n",
    "        init.orthogonal_(self.conv4.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "import torch.optim as optim\n",
    "model = Net(upscale_factor=2).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "train_set = get_training_set('./1080Dataset/')\n",
    "test_set = get_test_set('./1080Dataset/')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_set, batch_size=10)\n",
    "test_loader = torch.utils.data.DataLoader(test_set, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    epoch_loss = 0\n",
    "    for iteration, batch in enumerate(train_loader, 1):\n",
    "        input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(input), target)\n",
    "        epoch_loss += loss.item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    " \n",
    "        print(\"===> Epoch[{}]({}/{}): Loss: {:.4f}\".format(epoch, iteration, len(train_loader), loss.item()))\n",
    "\n",
    "    print(\"===> Epoch {} Complete: Avg. Loss: {:.4f}\".format(epoch, epoch_loss / len(train_loader)))\n",
    "\n",
    "def test():\n",
    "    avg_psnr = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in testing_data_loader:\n",
    "            input, target = batch[0].to(device), batch[1].to(device)\n",
    "\n",
    "            prediction = model(input)\n",
    "            mse = criterion(prediction, target)\n",
    "            psnr = 10 * log10(1 / mse.item())\n",
    "            avg_psnr += psnr\n",
    "    print(\"===> Avg. PSNR: {:.4f} dB\".format(avg_psnr / len(test_loader)))\n",
    "\n",
    "\n",
    "def checkpoint(epoch):\n",
    "    model_out_path = \"model_epoch_{}.pth\".format(epoch)\n",
    "    torch.save(model, model_out_path)\n",
    "    print(\"Checkpoint saved to {}\".format(model_out_path))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(1, 100):\n",
    "    train(epoch)\n",
    "    test()\n",
    "    checkpoint(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Rescale(object):\n",
    "    \n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, x2image = sample['image'], sample['x2image']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        if isinstance(self.output_size, int):\n",
    "            if h > w:\n",
    "                new_h, new_w = self.output_size * h / w, self.output_size\n",
    "            else:\n",
    "                new_h, new_w = self.output_size, self.output_size * w / h\n",
    "        else:\n",
    "            new_h, new_w = self.output_size\n",
    "\n",
    "        new_h, new_w = int(new_h), int(new_w)\n",
    "\n",
    "        img = transform.resize(image, (new_h, new_w))\n",
    "        x2img = transform.resize(x2image, (2 * new_h, 2 * new_w))\n",
    "\n",
    "\n",
    "        return {'image': img, 'x2image': x2img}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RandomCrop(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size):\n",
    "        assert isinstance(output_size, (int, tuple))\n",
    "        if isinstance(output_size, int):\n",
    "            self.output_size = (output_size, output_size)\n",
    "        else:\n",
    "            assert len(output_size) == 2\n",
    "            self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image, x2image = sample['image'], sample['x2image']\n",
    "\n",
    "        h, w = image.shape[:2]\n",
    "        new_h, new_w = self.output_size\n",
    "\n",
    "        top = np.random.randint(0, h - new_h)\n",
    "        left = np.random.randint(0, w - new_w)\n",
    "\n",
    "        image = image[top: top + new_h,\n",
    "                      left: left + new_w]\n",
    "\n",
    "        x2image = x2image[top: top + (new_h * 2),\n",
    "                      left: left + (new_w * 2)]\n",
    "\n",
    "        return {'image': image, 'x2image': x2image}\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
